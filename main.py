# streamlit_app.py
import numpy as np
import pandas as pd
import streamlit as st

from perceptron import min_max_normalize, entrenar_perceptron, activation

st.set_page_config(page_title="Perceptr√≥n Din√°mico", layout="wide")

st.title("üß† Perceptr√≥n Din√°mico con Normalizaci√≥n Min‚ÄìMax")
st.write(
    """
Interfaz gr√°fica para jugar con un perceptr√≥n de **cualquier n√∫mero de caracter√≠sticas (x‚ÇÅ...x‚Çô)**  
Usa el m√≥dulo `perceptron.py` (entrenamiento por √©pocas) con una UI mucho m√°s c√≥moda.
"""
)

# ===========================================================
# SECCI√ìN 1: DEFINICI√ìN DEL CONJUNTO DE ENTRENAMIENTO
# ===========================================================
st.header("Datos de entrenamiento")

col_n, col_hint = st.columns([1, 3])
with col_n:
    n_features = st.number_input(
        "N√∫mero de caracter√≠sticas (X) por patr√≥n",
        min_value=1,
        max_value=10,
        value=2,
        step=1,
    )

with col_hint:
    st.info(
        "Cada fila ser√° un patr√≥n de entrenamiento. Las columnas `x1...xn` son las caracter√≠sticas "
        "y la columna `y` es la salida deseada (0 o 1). Puedes agregar/eliminar filas."
    )

# Crear/actualizar DataFrame en sesi√≥n
if "df_train" not in st.session_state or st.session_state.get("df_train_n") != n_features:
    cols = [f"x{i+1}" for i in range(n_features)] + ["y"]
    data = [
        [0.0] * n_features + [0],
        [1.0] * n_features + [1],
    ]
    st.session_state.df_train = pd.DataFrame(data, columns=cols)
    st.session_state.df_train_n = n_features

df_train = st.data_editor(
    st.session_state.df_train,
    num_rows="dynamic",
    use_container_width=True,
    key="data_editor_train",
)
st.session_state.df_train = df_train  # guardar cambios


def preparar_datos(df, n_features: int):
    """Convierte el DataFrame a X (float) e y (int), validando NaNs."""
    if df.empty:
        st.error("‚ö† Debes tener al menos un patr√≥n de entrenamiento.")
        return None, None

    required_cols = [f"x{i+1}" for i in range(n_features)] + ["y"]
    for c in required_cols:
        if c not in df.columns:
            st.error(f"Falta la columna `{c}` en la tabla de datos.")
            return None, None

    # Eliminar filas completamente vac√≠as
    df_clean = df.dropna(how="all")
    if df_clean.empty:
        st.error("‚ö† Todos los patrones est√°n vac√≠os.")
        return None, None

    # Verificar NaNs en las columnas necesarias
    if df_clean[required_cols].isna().any().any():
        st.error("‚ö† No puede haber valores vac√≠os (NaN) en X o en y.")
        return None, None

    X = df_clean[[f"x{i+1}" for i in range(n_features)]].astype(float).to_numpy()
    y = df_clean["y"].astype(int).to_numpy()

    # Verificar que y solo contenga 0 o 1
    if not np.isin(y, [0, 1]).all():
        st.error("‚ö† La columna y solo puede contener 0 o 1.")
        return None, None

    return X, y


# ===========================================================
# SECCI√ìN 2: HIPERPAR√ÅMETROS DEL PERCEPTR√ìN
# ===========================================================
st.header("Par√°metros del modelo")

col_left, col_right = st.columns(2)

with col_left:
    init_mode = st.selectbox(
        "Inicializaci√≥n de pesos",
        options=["Ceros", "Aleatorios N(0,1)"],
        index=0,
    )

    b_init = st.number_input("Sesgo inicial (b)", value=0.0, step=0.1)

with col_right:
    eta = st.number_input(
        "Tasa de aprendizaje (Œ∑)",
        min_value=0.0001,
        max_value=1.0,
        value=0.1,
        step=0.01,
    )
    max_iter = st.number_input(
        "M√°ximo de iteraciones (√©pocas)",
        min_value=1,
        max_value=10_000,
        value=20,
        step=1,
    )

# ===========================================================
# SECCI√ìN 3: ENTRENAR EL MODELO
# ===========================================================
st.header("Entrenar perceptr√≥n")

train_button = st.button("üöÄ Entrenar", type="primary")

if train_button:
    X_raw, y = preparar_datos(df_train, n_features)
    if X_raw is not None:
        # Normalizar
        X_norm, X_min, X_max = min_max_normalize(X_raw)
        X_norm = np.round(X_norm, 2)

        st.subheader("Datos normalizados (Min‚ÄìMax)")
        st.dataframe(
            pd.DataFrame(
                X_norm,
                columns=[f"x{i+1}" for i in range(n_features)],
            ),
            use_container_width=True,
        )

        # Inicializar pesos
        if init_mode == "Ceros":
            w_init = np.zeros(n_features, dtype=float)
        else:
            w_init = np.random.randn(n_features).astype(float)

        st.write("Pesos iniciales:", w_init)
        st.write("Sesgo inicial:", b_init)

        # Entrenar usando la funci√≥n de tu m√≥dulo
        with st.spinner("Entrenando perceptr√≥n..."):
            w_final, b_final, historial = entrenar_perceptron(
                X_norm, y, w_init, b_init, eta, int(max_iter)
            )

        # Guardar en sesi√≥n para poder validar luego
        st.session_state.trained = True
        st.session_state.X_min = X_min
        st.session_state.X_max = X_max
        st.session_state.w_final = w_final
        st.session_state.b_final = b_final
        st.session_state.historial = historial
        st.session_state.n_features = n_features

        st.success("‚úÖ Entrenamiento completado")

        # ---------- RESUMEN POR √âPOCA ----------
        st.subheader("Resumen por iteraci√≥n (√©poca)")
        resumen_data = []
        for h in historial:
            resumen_data.append(
                {
                    "Iteraci√≥n": h["iter"],
                    "Errores": h["errores"],
                    "w": np.round(h["w"], 3),
                    "b": round(h["b"], 3),
                }
            )
        st.dataframe(pd.DataFrame(resumen_data), use_container_width=True)

        # Evoluci√≥n de errores
        st.subheader("Evoluci√≥n de errores por iteraci√≥n")
        errores_por_iter = pd.DataFrame(
            {
                "iter": [h["iter"] for h in historial],
                "errores": [h["errores"] for h in historial],
            }
        ).set_index("iter")
        st.line_chart(errores_por_iter)

        # ---------- TABLA DETALLADA PARA EL INFORME ----------
        st.subheader("Tabla detallada (para el informe)")

        # Construimos una sola tabla con TODAS las actualizaciones
        filas = []
        for h in historial:
            iter_idx = h["iter"]
            for r in h["registros"]:
                fila = {
                    "Iteraci√≥n": iter_idx,
                    "Patr√≥n": r["patron"],
                    "z": r["z"],
                    "≈∑": r["pred"],
                    "Error": r["error"],
                    "b": r["b"],
                }
                # Expandir vector de pesos en columnas w1...wn
                w_vec = np.array(r["w"], dtype=float)
                for j, val in enumerate(w_vec):
                    fila[f"w{j+1}"] = val
                filas.append(fila)

        df_full_log = pd.DataFrame(filas)

        st.dataframe(df_full_log, use_container_width=True)

        # Bot√≥n para descargar como CSV (para pegar en Excel/Word/LaTeX)
        csv_bytes = df_full_log.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="üíæ Descargar tabla completa (CSV)",
            data=csv_bytes,
            file_name="perceptron_entrenamiento_detalle.csv",
            mime="text/csv",
        )

        # Detalle por √©poca en un expander (si quer√©s verlo separado)
        with st.expander("üîé Ver detalle por √©poca"):
            for h in historial:
                st.markdown(f"#### Iteraci√≥n {h['iter']}")
                filas_epoch = []
                for r in h["registros"]:
                    fila = {
                        "Patr√≥n": r["patron"],
                        "z": r["z"],
                        "≈∑": r["pred"],
                        "Error": r["error"],
                        "b": r["b"],
                    }
                    w_vec = np.array(r["w"], dtype=float)
                    for j, val in enumerate(w_vec):
                        fila[f"w{j+1}"] = val
                    filas_epoch.append(fila)
                df_regs = pd.DataFrame(filas_epoch)
                st.dataframe(df_regs, use_container_width=True)

        st.subheader("Par√°metros finales del modelo")
        st.write("w_final:", np.round(w_final, 3))
        st.write("b_final:", round(b_final, 3))

# ===========================================================
# SECCI√ìN 4: VALIDACI√ìN DE NUEVOS DATOS
# ===========================================================
st.header("Validar nuevos datos")

if not st.session_state.get("trained", False):
    st.info("‚ö† Entrena el modelo primero para poder validar nuevos datos.")
else:
    X_min = st.session_state.X_min
    X_max = st.session_state.X_max
    w_final = st.session_state.w_final
    b_final = st.session_state.b_final
    n_features = st.session_state.n_features

    st.write(
        "Introduce un nuevo vector x = (x‚ÇÅ...x‚Çô) en la **escala original**. "
        "Se normalizar√° autom√°ticamente usando los min/max del conjunto de entrenamiento."
    )

    cols_inputs = st.columns(n_features)
    x_new = np.zeros(n_features, dtype=float)
    for i in range(n_features):
        with cols_inputs[i]:
            x_new[i] = st.number_input(
                f"x{i+1} (nuevo)",
                value=0.0,
                key=f"x_new_{i}",
            )

    if st.button("üìå Validar nuevo patr√≥n"):
        # Normalizar usando min y max originales
        x_norm = (x_new - X_min) / (X_max - X_min)
        x_norm = np.round(x_norm, 2)

        z = np.dot(w_final, x_norm) + b_final
        pred = activation(z)

        st.write("Vector original:", x_new)
        st.write("Vector normalizado:", x_norm)
        st.write(f"z = {z:.4f}")
        st.success(f"Predicci√≥n del perceptr√≥n: **{pred}** (0 = rechazo, 1 = aceptaci√≥n)")
